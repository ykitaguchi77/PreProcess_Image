{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled31.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/PreProcess_Image_colab/blob/master/EfficientNet_b4_ImageNet_adabound_ValidationTest.%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A6%E8%A7%A3%E6%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-a4ZBlqPNdU",
        "colab_type": "text"
      },
      "source": [
        "#**GravCont: EfficientNet_b4_ImageNet**\n",
        "ValidationとTestに分けて解析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgM-Y7SVPNkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "c9484092-97aa-4eb4-fffc-d51bd647d425"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "#Advanced Pytorchから\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set random seem for reproducibility\n",
        "manualSeed = 1234\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.cuda.manual_seed(manualSeed)\n",
        "\n",
        "torch.torch.backends.cudnn.benchmark = True\n",
        "torch.torch.backends.cudnn.enabled = True\n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet \n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "'''\n",
        "grav: 甲状腺眼症\n",
        "cont: コントロール\n",
        "黒の空白を挿入することにより225px*225pxの画像を生成、EfficientNetを用いて転移学習\n",
        "－－－－－－－－－－－－－－\n",
        "データの構造\n",
        "gravcont.zip ------grav\n",
        "               |---cont\n",
        "'''                                     \n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.6/dist-packages (0.0.1a15)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torch_optimizer) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch_optimizer) (0.16.0)\n",
            "Random Seed:  1234\n",
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzp_09fWPNoU",
        "colab_type": "text"
      },
      "source": [
        "#**モジュール群**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7sJV06qPNsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_process(data_dir):\n",
        "    # 入力画像の前処理をするクラス\n",
        "    # 訓練時と推論時で処理が異なる\n",
        "\n",
        "    \"\"\"\n",
        "        画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "        画像のサイズをリサイズし、色を標準化する。\n",
        "        訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
        "\n",
        "\n",
        "        Attributes\n",
        "        ----------\n",
        "        resize : int\n",
        "            リサイズ先の画像の大きさ。\n",
        "        mean : (R, G, B)\n",
        "            各色チャネルの平均値。\n",
        "        std : (R, G, B)\n",
        "            各色チャネルの標準偏差。\n",
        "    \"\"\"\n",
        "\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224, scale=(0.75,1.0)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    data_dir = data_dir\n",
        "    n_samples = len(data_dir)\n",
        "\n",
        "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                              data_transforms[x])\n",
        "                      for x in ['train', 'val']}\n",
        "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=20,\n",
        "                                                shuffle=True, num_workers=4)\n",
        "                  for x in ['train', 'val']}\n",
        "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "    class_names = image_datasets['train'].classes\n",
        "\n",
        "\n",
        "    print(class_names)\n",
        "    k=0\n",
        "    for i in class_names:\n",
        "        print(class_names[k]+\"_train:\"+str(len(os.listdir(path=data_dir + '/train/'+class_names[k]))))\n",
        "        k+=1\n",
        "    k=0\n",
        "    for i in class_names:\n",
        "        print(class_names[k]+\"_val:\"+str(len(os.listdir(path=data_dir + '/val/'+class_names[k]))))\n",
        "        k+=1\n",
        "\n",
        "    print(\"training data set_total：\"+ str(len(image_datasets['train'])))\n",
        "    print(\"validating data set_total：\"+str(len(image_datasets['val'])))\n",
        "    \n",
        "    return image_datasets, dataloaders, dataset_sizes, class_names, device\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "def getBatch(dataloaders):    \n",
        "    # Get a batch of training data\n",
        "    inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "    # Make a grid from batch\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "    #imshow(out, title=[class_names[x] for x in classes])\n",
        "    return(inputs, classes)\n",
        "\n",
        "#Defining early stopping class\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_loss = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_loss = []\n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase] \n",
        "            \n",
        "            # record train_loss and valid_loss\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "            if phase == 'val':\n",
        "                valid_loss.append(epoch_loss)\n",
        "            #print(train_loss)\n",
        "            #print(valid_loss)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "      \n",
        "      # early_stopping needs the validation loss to check if it has decresed, \n",
        "      # and if it has, it will make a checkpoint of the current model\n",
        "        if phase == 'val':    \n",
        "            early_stopping(epoch_loss, model)\n",
        "                \n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "        print()\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_loss, valid_loss\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "def convnet():\n",
        "    model_ft = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "    num_ftrs = model_ft._fc.in_features\n",
        "    model_ft._fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    optimizer_ft = optim.AdaBound(\n",
        "        model_ft.parameters(),\n",
        "        lr= 1e-3,\n",
        "        betas= (0.9, 0.999),\n",
        "        final_lr = 0.1,\n",
        "        gamma=1e-3,\n",
        "        eps= 1e-8,\n",
        "        weight_decay=0,\n",
        "        amsbound=False,\n",
        "    )\n",
        "    return (model_ft, criterion, optimizer_ft)\n",
        "\n",
        "\n",
        "def training(model_ft, criterion, optimizer_ft,  patience=15, num_epochs=50):\n",
        "    model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=patience, num_epochs=num_epochs)\n",
        "\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      return(image_name, label)\n",
        "\n",
        "'''\n",
        "#変形後の画像を表示\n",
        "def image_transform(image_path):\n",
        "\n",
        "    image=Image.open(image_path)\n",
        "\n",
        "    \n",
        "    #変形した画像を表示する\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224)])\n",
        "    image_transformed = transform(image)\n",
        "    plt.imshow(np.array(image_transformed))\n",
        "'''\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を表示\n",
        "def image_eval(image_tensor, label):\n",
        "    output = model_ft(image_tensor)\n",
        "    #print(output.size())  # torch.Size([1, 1000])\n",
        "    #print(output)\n",
        "\n",
        "    #model_pred:クラス名前、prob:確率、pred:クラス番号\n",
        "    prob, pred = torch.topk(nn.Softmax(dim=1)(output), 1)\n",
        "    model_pred = class_names[pred]\n",
        "    \n",
        "    #甲状腺眼症のprobabilityを計算（classが0なら1から減算、classが1ならそのまま）\n",
        "    prob = abs(1-float(prob)-float(pred))\n",
        " \n",
        "    return model_pred, prob, pred\n",
        "\n",
        "    \"\"\"\n",
        "    #probalilityを計算する\n",
        "    pred_prob = torch.topk(nn.Softmax(dim=1)(output), 1)[0]\n",
        "    pred_class = torch.topk(nn.Softmax(dim=1)(output), 1)[1]\n",
        "    if pred_class == 1:\n",
        "        pred_prob = pred_prob\n",
        "    elif pred_class == 0:\n",
        "        pred_prob = 1- pred_prob\n",
        "    return(model_pred, pred_prob)  #class_nameの番号で出力される\n",
        "    \"\"\"\n",
        "\n",
        "def showImage(image_path):\n",
        "    #画像のインポート\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    #画像のリサイズ\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    resized_img = cv2.resize(img, (int(width*300/height), 300))\n",
        "    cv2_imshow(resized_img)\n",
        "\n",
        "def calculateAccuracy (TP, TN, FP, FN):\n",
        "    accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "    precision  = TP/(FP + TP)\n",
        "    recall = TP/(TP + FN)\n",
        "    specificity = TN/(FP + TN)\n",
        "    f_value = (2*recall*precision)/(recall+precision)\n",
        "    return(accuracy, precision, recall, specificity, f_value)\n",
        "\n",
        "\"\"\"\n",
        "・True positive (TN)\n",
        "・False positive (FP)\n",
        "・True negative (TN)\n",
        "・False negative (FN)\n",
        "Accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "Precision = TP/(FP + TP) ※positive predictive value\n",
        "Recall = TP/(TP + FN)　※sensitivity\n",
        "Specificity = TN/(FP + TN)\n",
        "F_value = (2RecallPrecision)/(Recall+Precision)\n",
        "\"\"\"\n",
        "\n",
        "def evaluation(model_ft):\n",
        "    #評価モードにする\n",
        "    model_ft.eval()\n",
        "\n",
        "    #testデータセット内のファイル名を取得\n",
        "    image_path = glob.glob(\"/content/drive/My Drive/Grav_bootcamp/Posttrain_250px/*/*\")\n",
        "    #random.shuffle(image_path)  #表示順をランダムにする\n",
        "    print('number of images: ' +str(len(image_path)))\n",
        "\n",
        "\n",
        "    TP, FP, TN, FN, TP, FP, TN, FN = [0,0,0,0,0,0,0,0]\n",
        "    image_name_list = []\n",
        "    label_list = []\n",
        "    model_pred_list = []\n",
        "    hum_pred_list = []\n",
        "\n",
        "    model_pred_class = []\n",
        "    model_pred_prob = []\n",
        "\n",
        "    for i in image_path:\n",
        "          image_name, label = getlabel(i)  #画像の名前とラベルを取得\n",
        "          image_tensor = image_transform(i)  #予測のための画像下処理\n",
        "          model_pred, prob, pred = image_eval(image_tensor, label)  #予測結果を出力   \n",
        "          #print('Image: '+ image_name)\n",
        "          #print('Label: '+ label)\n",
        "          #print('Pred: '+ model_pred)\n",
        "          #showImage(i)  #画像を表示\n",
        "          #print() #空白行を入れる\n",
        "          time.sleep(0.1)\n",
        "\n",
        "          image_name_list.append(image_name)\n",
        "          label_list.append(label)\n",
        "          model_pred_list.append(model_pred)\n",
        "\n",
        "          model_pred_class.append(int(pred))\n",
        "          model_pred_prob.append(float(prob))\n",
        "\n",
        "          if label == class_names[0]:\n",
        "              if model_pred == class_names[0]:\n",
        "                  TN += 1\n",
        "              else:\n",
        "                  FP += 1\n",
        "          elif label == class_names[1]:\n",
        "              if model_pred == class_names[1]:\n",
        "                  TP += 1\n",
        "              else:\n",
        "                  FN += 1     \n",
        "\n",
        "    print(TP, FN, TN, FP)\n",
        "\n",
        "    #Accuracyを計算\n",
        "    accuracy, precision, recall, specificity, f_value = calculateAccuracy (TP, TN, FP, FN)\n",
        "    print('Accuracy: ' + str(accuracy))\n",
        "    print('Precision (positive predictive value): ' + str(precision))\n",
        "    print('Recall (sensitivity): ' + str(recall))\n",
        "    print('Specificity: ' + str(specificity))\n",
        "    print('F_value: ' + str(f_value))\n",
        "\n",
        "    print(model_pred_class)\n",
        "    print(model_pred_prob)\n",
        "\n",
        "    return TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, label_list, model_pred_prob\n",
        "\n",
        "\n",
        "def make_csv():\n",
        "    #csvのdata tableを作成\n",
        "    pd.set_option('display.max_rows', 800)  # 省略なしで表示\n",
        "    columns1 = [\"EfficientNet_32\", \"EfficientNet_64\", \"EfficientNet_128\", \"EfficientNet_256\", \"EfficientNet_512\", \"EfficientNet_558\"]\n",
        "    index1 = [\"TP\",\"TN\",\"FP\",\"FN\",\"Accuracy\",\"Positive predictive value\",\"sensitity\",\"specificity\",\"F-value\",\"roc_auc\"]\n",
        "    df = pd.DataFrame(index=index1, columns=columns1)\n",
        "    return df\n",
        "\n",
        "def write_csv(df, col, TP, TN, FP, FN, accuracy, precision, recall, specificity, f_value,roc_auc):\n",
        "    df.iloc[0:10, col] = TP, TN, FP, FN, accuracy, precision, recall, specificity, f_value,roc_auc \n",
        "    #print(df)\n",
        "\n",
        "    # CSVとして出力\n",
        "    #df2.to_csv(\"/content/drive/My Drive/Grav_bootcamp/Posttrain_model_eval_result.csv\",encoding=\"shift_jis\")\n",
        "    return df\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    ycolor = ['darkorange','blue','green','red','black']      # 各プロットの色\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == 'cont':\n",
        "                  y_true.append(0)\n",
        "            elif i == 'grav':\n",
        "                  y_true.append(1)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list)+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob):\n",
        "    for i in label_list[0]:\n",
        "        if i == 'cont':\n",
        "              y_true.append(0)\n",
        "        elif i == 'grav':\n",
        "              y_true.append(1)\n",
        "            \n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(roc_auc)\n",
        "    return(roc_auc)"
      ],
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USGfUwQXv6Jc",
        "colab_type": "text"
      },
      "source": [
        "#**まとめて解析**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM2VMXltwBs5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d78fa5ff-2d3d-440f-8758-609efb2826b3"
      },
      "source": [
        "data_dir_list = ['/content/drive/My Drive/Grav_bootcamp/PrePlusTrain_32','/content/drive/My Drive/Grav_bootcamp/PrePlusTrain_64','/content/drive/My Drive/Grav_bootcamp/PrePlusTrain_128','/content/drive/My Drive/Grav_bootcamp/PrePlusTrain_256','/content/drive/My Drive/Grav_bootcamp/PrePlusTrain_512','/content/drive/My Drive/Grav_bootcamp/PrePlusTrain_558']\n",
        "data_dir_list = data_dir_list[0:6]\n",
        "roc_label_list = ['n=32', 'n=64', 'n=128', 'n=256','n=512','n=558']\n",
        "\n",
        "df = make_csv()\n",
        "\n",
        "label_list_list, model_pred_prob_list = [],[]\n",
        "\n",
        "for i, t in enumerate(zip(data_dir_list, sample_num_list)):\n",
        "    image_datasets, dataloaders, dataset_sizes, class_names, device = pre_process(t[0]) #path\n",
        "    inputs, classes = getBatch(dataloaders)\n",
        "    model_ft, criterion, optimizer_ft = convnet()\n",
        "    training(model_ft, criterion, optimizer_ft,  patience=15, num_epochs=100)  \n",
        "    TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, label_list, model_pred_prob = evaluation(model_ft)\n",
        "    roc_auc = calculate_auc(label_list, model_pred_prob)\n",
        "    df = write_csv(df, i,TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, roc_auc) #numberをcsvの行として指定\n",
        "\n",
        "\n",
        "    label_list_list.append(label_list)\n",
        "    model_pred_prob_list.append(model_pred_prob)\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "\n",
        "#Draw ROC curve\n",
        "fig = Draw_roc_curve(label_list_list, model_pred_prob_list, roc_label_list, len(label_list_list))\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', 100)\n",
        "print(df)\n",
        "\n",
        "\n",
        "# CSVとして出力\n",
        "df.to_csv(\"/content/drive/My Drive/Grav_bootcamp/Posttrain_model_eval_result.csv\",encoding=\"shift_jis\")\n",
        "\n",
        "#ROC_curveを保存\n",
        "fig.savefig(\"/content/drive/My Drive/Grav_bootcamp/img.png\")\n",
        "\n"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cont', 'grav']\n",
            "cont_train:12\n",
            "grav_train:11\n",
            "cont_val:4\n",
            "grav_val:4\n",
            "training data set_total：23\n",
            "validating data set_total：8\n",
            "Loaded pretrained weights for efficientnet-b4\n",
            "Epoch 0/2\n",
            "----------\n",
            "train Loss: 0.6551 Acc: 0.6522\n",
            "val Loss: 0.6929 Acc: 0.5000\n",
            "Validation loss decreased (inf --> 0.692884).  Saving model ...\n",
            "\n",
            "Epoch 1/2\n",
            "----------\n",
            "train Loss: 0.3722 Acc: 0.9565\n",
            "val Loss: 0.6497 Acc: 0.7500\n",
            "Validation loss decreased (0.692884 --> 0.649718).  Saving model ...\n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "train Loss: 0.2775 Acc: 0.9130\n",
            "val Loss: 0.5296 Acc: 0.7500\n",
            "Validation loss decreased (0.649718 --> 0.529575).  Saving model ...\n",
            "\n",
            "Training complete in 0m 6s\n",
            "Best val Acc: 0.750000\n",
            "number of images: 108\n",
            "20 34 40 14\n",
            "Accuracy: 0.5555555555555556\n",
            "Precision (positive predictive value): 0.5882352941176471\n",
            "Recall (sensitivity): 0.37037037037037035\n",
            "Specificity: 0.7407407407407407\n",
            "F_value: 0.45454545454545453\n",
            "[0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "[0.4699128270149231, 0.5462020635604858, 0.44575607776641846, 0.49740707874298096, 0.44754457473754883, 0.6407657861709595, 0.4941183924674988, 0.5414077639579773, 0.5258081555366516, 0.4964671730995178, 0.5101503729820251, 0.5254928469657898, 0.4745413661003113, 0.4164953827857971, 0.44055837392807007, 0.477255642414093, 0.49456357955932617, 0.526779294013977, 0.5200744867324829, 0.5073444843292236, 0.453636109828949, 0.5044712424278259, 0.4608422517776489, 0.5044482946395874, 0.4815831780433655, 0.4948219656944275, 0.48411494493484497, 0.4479147791862488, 0.5149363875389099, 0.4255162477493286, 0.49320852756500244, 0.6761842370033264, 0.5300596952438354, 0.5255783200263977, 0.46293318271636963, 0.4485602378845215, 0.4324854016304016, 0.49516773223876953, 0.6590321660041809, 0.43252772092819214, 0.44370949268341064, 0.44411319494247437, 0.4392045736312866, 0.4347112774848938, 0.544956386089325, 0.3838188052177429, 0.4537087678909302, 0.5088984370231628, 0.44592684507369995, 0.5768555998802185, 0.4385363459587097, 0.5124118328094482, 0.40804821252822876, 0.4889175295829773, 0.5881155133247375, 0.4217531085014343, 0.5216901898384094, 0.4353257417678833, 0.5277342200279236, 0.5020473003387451, 0.49229204654693604, 0.5700929760932922, 0.45705777406692505, 0.4777258038520813, 0.4788835644721985, 0.41608160734176636, 0.5100585222244263, 0.49977731704711914, 0.4693334102630615, 0.4886276125907898, 0.46407395601272583, 0.46603304147720337, 0.48979371786117554, 0.4499027729034424, 0.4221837520599365, 0.5169101357460022, 0.56095951795578, 0.5209263563156128, 0.5243574380874634, 0.38430023193359375, 0.4537160396575928, 0.44004201889038086, 0.459445059299469, 0.4577455520629883, 0.4759036898612976, 0.44552797079086304, 0.460357129573822, 0.4645090103149414, 0.5470401644706726, 0.5415454506874084, 0.4341481328010559, 0.4517146348953247, 0.43007320165634155, 0.47597306966781616, 0.4702606797218323, 0.4513164162635803, 0.44759994745254517, 0.4284716248512268, 0.5028315782546997, 0.46458327770233154, 0.44129008054733276, 0.43111652135849, 0.42181867361068726, 0.497478723526001, 0.471499502658844, 0.44930499792099, 0.4304041266441345, 0.534835159778595]\n",
            "0.5692729766803841\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "                          EfficientNet_32 EfficientNet_64 EfficientNet_128  \\\n",
            "TP                                     20             NaN              NaN   \n",
            "TN                                     40             NaN              NaN   \n",
            "FP                                     14             NaN              NaN   \n",
            "FN                                     34             NaN              NaN   \n",
            "Accuracy                         0.555556             NaN              NaN   \n",
            "Positive predictive value        0.588235             NaN              NaN   \n",
            "sensitity                         0.37037             NaN              NaN   \n",
            "specificity                      0.740741             NaN              NaN   \n",
            "F-value                          0.454545             NaN              NaN   \n",
            "roc_auc                          0.569273             NaN              NaN   \n",
            "\n",
            "                          EfficientNet_256 EfficientNet_512 EfficientNet_558  \n",
            "TP                                     NaN              NaN              NaN  \n",
            "TN                                     NaN              NaN              NaN  \n",
            "FP                                     NaN              NaN              NaN  \n",
            "FN                                     NaN              NaN              NaN  \n",
            "Accuracy                               NaN              NaN              NaN  \n",
            "Positive predictive value              NaN              NaN              NaN  \n",
            "sensitity                              NaN              NaN              NaN  \n",
            "specificity                            NaN              NaN              NaN  \n",
            "F-value                                NaN              NaN              NaN  \n",
            "roc_auc                                NaN              NaN              NaN  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPO-b2cAT0yF",
        "colab_type": "text"
      },
      "source": [
        "#**ネットワークの保存と読み込み**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMYyFQ6ATzyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ネットワークの保存\n",
        "PATH = '/content/drive/My Drive/Grav_bootcamp/GravCont_EfficientNet-b4_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "torch.save(model_ft.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c744XUtfT6xW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73a923de-e875-4e71-b4b5-1ae266557981"
      },
      "source": [
        "#ネットワークの読み込み\n",
        "PATH = '/content/drive/My Drive/Grav_bootcamp/GravCont_EfficientNet-b4_ImageNet_seed'+str(manualSeed)+'.pth'\n",
        "torch.save(model_ft.state_dict(), PATH)\n",
        "model_ft.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}